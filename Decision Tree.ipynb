{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f8fcbaeb-888a-4b0b-98fd-3edb245e4004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "→ Entropy of dataset: 0.9403\n",
      "Information Gain (Age): 0.2467\n",
      "Information Gain (Income): 0.0292\n",
      "Information Gain (Student): 0.2361\n",
      "Information Gain (Credit_rating): 0.0481\n",
      "\n",
      "Best feature to split: Age\n",
      "\n",
      "→ Entropy of dataset: 0.9710\n",
      "Information Gain (Income): 0.5710\n",
      "Information Gain (Student): 0.9710\n",
      "Information Gain (Credit_rating): 0.0200\n",
      "\n",
      "Best feature to split: Student\n",
      "\n",
      "→ Entropy of dataset: 0.9710\n",
      "Information Gain (Income): 0.0200\n",
      "Information Gain (Student): 0.0200\n",
      "Information Gain (Credit_rating): 0.9710\n",
      "\n",
      "Best feature to split: Credit_rating\n",
      "\n",
      "\n",
      "Final Decision Tree:\n",
      "{'Age': {'middle-aged': 'yes', 'youth': {'Student': {'yes': 'yes', 'no': 'no'}}, 'senior': {'Credit_rating': {'excellent': 'no', 'fair': 'yes'}}}}\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "# Data\n",
    "data = { \n",
    "    'Age': ['youth', 'youth', 'middle-aged', 'senior', 'senior', 'senior', 'middle-aged', 'youth', 'youth', 'senior', 'youth', 'middle-aged', 'middle-aged', 'senior'], \n",
    "    'Income': ['high', 'high', 'high', 'medium', 'low', 'low', 'low', 'medium', 'low', 'medium', 'medium', 'medium', 'high', 'medium'], \n",
    "    'Student': ['no', 'no', 'no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no'], \n",
    "    'Credit_rating': ['fair', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'fair', 'fair', 'excellent', 'excellent', 'fair', 'excellent'], \n",
    "    'Buys_Computer': ['no', 'no', 'yes', 'yes', 'yes', 'no', 'yes', 'no', 'yes', 'yes', 'yes', 'yes', 'yes', 'no'] \n",
    "}\n",
    "\n",
    "features = ['Age', 'Income', 'Student', 'Credit_rating']\n",
    "target = 'Buys_Computer'\n",
    "\n",
    "# === Helper Functions ===\n",
    "\n",
    "def entropy_of_dataset_Info_D(dataset):\n",
    "    \"\"\"Calculate entropy of the target values in the dataset.\"\"\"\n",
    "    yes_count = dataset[target].count('yes')\n",
    "    no_count = dataset[target].count('no')\n",
    "    total = yes_count + no_count\n",
    "\n",
    "    if total == 0:\n",
    "        return 0\n",
    "\n",
    "    p_yes = yes_count / total\n",
    "    p_no = no_count / total\n",
    "\n",
    "    entropy = 0\n",
    "    if p_yes > 0:\n",
    "        entropy -= p_yes * math.log2(p_yes)\n",
    "    if p_no > 0:\n",
    "        entropy -= p_no * math.log2(p_no)\n",
    "\n",
    "    print(f\"→ Entropy of dataset: {entropy:.4f}\")\n",
    "    return entropy\n",
    "\n",
    "def entropy_after_split(dataset, feature):\n",
    "    \"\"\"Compute expected entropy after splitting on a feature.\"\"\"\n",
    "    total = len(dataset[target])\n",
    "    values = set(dataset[feature])\n",
    "    entropy = 0\n",
    "\n",
    "    for val in values:\n",
    "        subset_yes = 0\n",
    "        subset_no = 0\n",
    "        subset_total = 0\n",
    "\n",
    "        for i in range(total):\n",
    "            if dataset[feature][i] == val:\n",
    "                subset_total += 1\n",
    "                if dataset[target][i] == 'yes':\n",
    "                    subset_yes += 1\n",
    "                else:\n",
    "                    subset_no += 1\n",
    "\n",
    "        if subset_total == 0:\n",
    "            continue\n",
    "\n",
    "        p_yes = subset_yes / subset_total\n",
    "        p_no = subset_no / subset_total\n",
    "        subset_entropy = 0\n",
    "        if p_yes > 0:\n",
    "            subset_entropy -= p_yes * math.log2(p_yes)\n",
    "        if p_no > 0:\n",
    "            subset_entropy -= p_no * math.log2(p_no)\n",
    "\n",
    "        entropy += (subset_total / total) * subset_entropy\n",
    "\n",
    "    return entropy\n",
    "\n",
    "def info_gain(dataset, base_entropy, feature):\n",
    "    \"\"\"Information Gain from splitting on a feature.\"\"\"\n",
    "    gain = base_entropy - entropy_after_split(dataset, feature)\n",
    "    print(f\"Information Gain ({feature}): {gain:.4f}\")\n",
    "    return gain\n",
    "\n",
    "def get_best_feature(dataset, features, base_entropy):\n",
    "    \"\"\"Select the feature with the highest information gain.\"\"\"\n",
    "    best = None\n",
    "    max_gain = -1\n",
    "    for feature in features:\n",
    "        gain = info_gain(dataset, base_entropy, feature)\n",
    "        if gain > max_gain:\n",
    "            max_gain = gain\n",
    "            best = feature\n",
    "    return best\n",
    "\n",
    "def majority_class(labels):\n",
    "    \"\"\"Return the most common class label.\"\"\"\n",
    "    freq = {}\n",
    "    for label in labels:\n",
    "        freq[label] = freq.get(label, 0) + 1\n",
    "    return max(freq, key=freq.get)\n",
    "\n",
    "# === Tree Builder ===\n",
    "\n",
    "def build_tree(dataset, features):\n",
    "    # If all target values are the same\n",
    "    if dataset[target].count(dataset[target][0]) == len(dataset[target]):\n",
    "        return dataset[target][0]\n",
    "\n",
    "    # If no more features, return majority class\n",
    "    if not features:\n",
    "        return majority_class(dataset[target])\n",
    "\n",
    "    base_entropy = entropy_of_dataset(dataset)\n",
    "    best_feature = get_best_feature(dataset, features, base_entropy)\n",
    "    tree = {best_feature: {}}\n",
    "    print(f\"\\nBest feature to split: {best_feature}\\n\")\n",
    "\n",
    "    unique_vals = set(dataset[best_feature])\n",
    "\n",
    "    for val in unique_vals:\n",
    "        # Create subset for this value\n",
    "        subset = {k: [] for k in dataset}\n",
    "        for i in range(len(dataset[best_feature])):\n",
    "            if dataset[best_feature][i] == val:\n",
    "                for k in dataset:\n",
    "                    subset[k].append(dataset[k][i])\n",
    "\n",
    "        remaining_features = [f for f in features if f != best_feature]\n",
    "        subtree = build_tree(subset, remaining_features)\n",
    "        tree[best_feature][val] = subtree\n",
    "\n",
    "    return tree\n",
    "\n",
    "# === Run ===\n",
    "\n",
    "decision_tree = build_tree(data, features)\n",
    "print(\"\\nFinal Decision Tree:\")\n",
    "print(decision_tree)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d220ed1-69e3-49bb-bf33-5ec957f7d6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
