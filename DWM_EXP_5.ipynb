{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMl7sGpOkX1xJEIZDNj/H6x",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Arpitd07/DWM-Experiments/blob/main/DWM_EXP_5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from itertools import combinations\n",
        "\n",
        "# Function to get frequent itemsets based on minimum support\n",
        "def get_frequent_itemsets(transactions, min_support):\n",
        "    itemsets = {}\n",
        "    for transaction in transactions:\n",
        "        for item in transaction:\n",
        "            if item in itemsets:\n",
        "                itemsets[item] += 1\n",
        "            else:\n",
        "                itemsets[item] = 1\n",
        "\n",
        "    # Filter itemsets to only include those that meet or exceed the minimum support\n",
        "    frequent_itemsets = {item: support for item, support in itemsets.items() if support >= min_support}\n",
        "    return frequent_itemsets\n",
        "\n",
        "# Function to generate candidate itemsets of size k\n",
        "def get_candidate_itemsets(frequent_itemsets, k):\n",
        "    candidates = []\n",
        "    frequent_items = list(frequent_itemsets.keys())\n",
        "    for combination in combinations(frequent_items, k):\n",
        "        candidates.append(combination)\n",
        "    return candidates\n",
        "\n",
        "\n",
        "# Apriori algorithm to find all frequent itemsets\n",
        "def apriori(transactions, min_support):\n",
        "    k = 1\n",
        "    # Initial set of frequent itemsets\n",
        "    frequent_itemsets = get_frequent_itemsets(transactions, min_support)\n",
        "    all_frequent_itemsets = [frequent_itemsets]\n",
        "\n",
        "    # Iterate to find larger itemsets\n",
        "    while frequent_itemsets:\n",
        "        k += 1\n",
        "        # Generate candidate itemsets of size k\n",
        "        candidates = get_candidate_itemsets(frequent_itemsets, k)\n",
        "        candidate_supports = {candidate: 0 for candidate in candidates}\n",
        "\n",
        "        # Calculate support for each candidate itemset\n",
        "        for transaction in transactions:\n",
        "            for candidate in candidates:\n",
        "                if set(candidate).issubset(set(transaction)):\n",
        "                    candidate_supports[candidate] += 1\n",
        "\n",
        "        # Filter candidate itemsets to only include those that meet or exceed the minimum support\n",
        "        frequent_itemsets = {itemset: support for itemset, support in candidate_supports.items() if support >= min_support}\n",
        "        if frequent_itemsets:\n",
        "            all_frequent_itemsets.append(frequent_itemsets)\n",
        "\n",
        "    return all_frequent_itemsets\n",
        "\n",
        "\n",
        "transactions = [\n",
        "    ['Milk', 'Bread', 'Nutella'],\n",
        "    ['Bread', 'Nutella'],\n",
        "    ['Milk', 'Bread', 'Sugar', 'Nutella'],\n",
        "    ['Milk', 'Bread'],\n",
        "    ['Milk', 'Sugar'],\n",
        "    ['Bread', 'Sugar', 'Nutella'],\n",
        "    ['Milk', 'Nutella']\n",
        "]\n",
        "\n",
        "min_support = 2\n",
        "frequent_itemsets = apriori(transactions, min_support)\n",
        "print(frequent_itemsets)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0KMAB8oqoKR7",
        "outputId": "6ed22b81-8429-47f1-8f94-fcd6e95e79a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[{'Milk': 5, 'Bread': 5, 'Nutella': 5, 'Sugar': 3}, {('Milk', 'Bread'): 3, ('Milk', 'Nutella'): 3, ('Milk', 'Sugar'): 2, ('Bread', 'Nutella'): 4, ('Bread', 'Sugar'): 2, ('Nutella', 'Sugar'): 2}]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oXuYsWKQnKJ_",
        "outputId": "2cfd3ed8-e5df-4347-cf75-f9a678260d85"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Frequent Itemsets:\n",
            "     support          itemsets\n",
            "0  0.714286           (Bread)\n",
            "1  0.714286            (Milk)\n",
            "2  0.714286         (Nutella)\n",
            "3  0.428571           (Sugar)\n",
            "4  0.428571     (Milk, Bread)\n",
            "5  0.571429  (Nutella, Bread)\n",
            "6  0.428571   (Milk, Nutella)\n",
            "\n",
            "Association Rules:\n",
            "   antecedents consequents   support  confidence  lift\n",
            "0      (Milk)     (Bread)  0.428571         0.6  0.84\n",
            "1     (Bread)      (Milk)  0.428571         0.6  0.84\n",
            "2   (Nutella)     (Bread)  0.571429         0.8  1.12\n",
            "3     (Bread)   (Nutella)  0.571429         0.8  1.12\n",
            "4      (Milk)   (Nutella)  0.428571         0.6  0.84\n",
            "5   (Nutella)      (Milk)  0.428571         0.6  0.84\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/mlxtend/frequent_patterns/fpcommon.py:161: DeprecationWarning: DataFrames with non-bool types result in worse computationalperformance and their support might be discontinued in the future.Please use a DataFrame with bool type\n",
            "  warnings.warn(\n"
          ]
        }
      ],
      "source": [
        "# Import required libraries\n",
        "import pandas as pd\n",
        "from mlxtend.frequent_patterns import apriori, association_rules\n",
        "\n",
        "data = {'Transaction': [\n",
        "    ['Milk', 'Bread', 'Nutella'],\n",
        "    ['Bread', 'Nutella'],\n",
        "    ['Milk', 'Bread', 'Sugar', 'Nutella'],\n",
        "    ['Milk', 'Bread'],\n",
        "    ['Milk', 'Sugar'],\n",
        "    ['Bread', 'Sugar', 'Nutella'],\n",
        "    ['Milk', 'Nutella']\n",
        "]}\n",
        "\n",
        "# Convert dataset into DataFrame\n",
        "df = pd.DataFrame(data['Transaction'])\n",
        "\n",
        "# Convert transaction data into one-hot encoded format\n",
        "basket = pd.get_dummies(df.apply(pd.Series).stack()).groupby(level=0).sum()\n",
        "\n",
        "# Set minimum support and confidence\n",
        "min_support = 0.3\n",
        "min_confidence = 0.6\n",
        "\n",
        "# Apply Apriori algorithm to get frequent itemsets\n",
        "frequent_itemsets = apriori(basket, min_support=min_support, use_colnames=True)\n",
        "\n",
        "# Generate association rules\n",
        "rules = association_rules(frequent_itemsets, metric=\"confidence\", min_threshold=min_confidence)\n",
        "\n",
        "# Display results\n",
        "print(\"Frequent Itemsets:\\n\", frequent_itemsets)\n",
        "print(\"\\nAssociation Rules:\\n\", rules[['antecedents', 'consequents', 'support', 'confidence', 'lift']])\n"
      ]
    }
  ]
}